{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhlmrLspneD/4zIg29t5I3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kritikachugh/Python_basics/blob/master/Searching_genes_by_name_in_gff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Reading a CSV file and returning it into data frame.**"
      ],
      "metadata": {
        "id": "7Z9c4jKG_XFW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3r9Y2qRcen8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df_csv = pd.read_csv('your_file.csv')\n",
        "# Print the DataFrame\n",
        "print(df_csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Filtering rows where 'No. isolates' is equal to 43**"
      ],
      "metadata": {
        "id": "Kiy5nH-V_fmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where 'No. isolates' is equal to 43\n",
        "filtered_df = df[df['No. isolates'] == 43]\n",
        "\n",
        "# Print the filtered DataFrame\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "id": "fclc1WIYcruk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. listing the names of all the genes where No. isolates = 43**"
      ],
      "metadata": {
        "id": "2Bf7hGIL_npQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list the names of all the genes where No. isolates = 43\n",
        "\n",
        "# Assuming 'Gene' is the column containing gene names\n",
        "gene_names = filtered_df['Gene'].tolist()\n",
        "\n",
        "# Print the list of gene names\n",
        "print(gene_names)\n"
      ],
      "metadata": {
        "id": "ThSmTtN5M5QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**This is for my understanding"
      ],
      "metadata": {
        "id": "wJ8n6vNFCFIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: code for parsing gff file in python\n",
        "\n",
        "def parse_gff(gff_file):\n",
        "  \"\"\"\n",
        "  Parses a GFF file and returns a list of features.\n",
        "\n",
        "  Args:\n",
        "    gff_file: Path to the GFF file.\n",
        "\n",
        "  Returns:\n",
        "    A list of dictionaries, where each dictionary represents a feature.\n",
        "  \"\"\"\n",
        "  features = []\n",
        "  with open(gff_file, 'r') as f:\n",
        "    for line in f:\n",
        "      if line.startswith('#'):\n",
        "        continue  # Skip comment lines\n",
        "      fields = line.strip().split('\\t')\n",
        "      if len(fields) < 9:\n",
        "        continue  # Skip lines with insufficient fields\n",
        "      seqid = fields[0]\n",
        "      source = fields[1]\n",
        "      ftype = fields[2]\n",
        "      start = int(fields[3])\n",
        "      end = int(fields[4])\n",
        "      score = fields[5]\n",
        "      strand = fields[6]\n",
        "      phase = fields[7]\n",
        "      attributes = fields[8]\n",
        "      # Parse attributes\n",
        "      attr_dict = {}\n",
        "      for attr in attributes.split(';'):\n",
        "        if '=' in attr:\n",
        "          key, value = attr.split('=')\n",
        "          attr_dict[key] = value\n",
        "      # Create feature dictionary\n",
        "      feature = {\n",
        "          'seqid': seqid,\n",
        "          'source': source,\n",
        "          'type': ftype,\n",
        "          'start': start,\n",
        "          'end': end,\n",
        "          'score': score,\n",
        "          'strand': strand,\n",
        "          'phase': phase,\n",
        "          'attributes': attr_dict\n",
        "      }\n",
        "      features.append(feature)\n",
        "  return features\n",
        "\n"
      ],
      "metadata": {
        "id": "S-7OrNZvctia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "gff_directory = '/scratch/zxx091000/fromMZ/Databases/Ecoli/Roary.April2024/results/fixed_input_files'\n",
        "gff_files = [f for f in os.listdir(gff_directory) if f.endswith('.gff')]\n",
        "for file in gff_files:\n",
        "    print(file)\n",
        "    gff = parse_gff(os.path.join(gff_directory, file))\n",
        "\n"
      ],
      "metadata": {
        "id": "sWh4YnIS73tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is for my understanding"
      ],
      "metadata": {
        "id": "1yXE2jajCKZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "        'Age': [18, 19, 17, 20, 18],\n",
        "        'Marks': [85, 92, 78, 95, 88]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rncqWEJJ9iQ",
        "outputId": "9013fe6b-d47b-4af7-f5a6-5a2b2518bd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name  Age  Marks\n",
            "0    Alice   18     85\n",
            "1      Bob   19     92\n",
            "2  Charlie   17     78\n",
            "3    David   20     95\n",
            "4      Eve   18     88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (df['Age'] > 17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ta8tMaWKeAT",
        "outputId": "c66e1519-1183-499d-d8d1-323a90337d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     True\n",
            "1     True\n",
            "2    False\n",
            "3     True\n",
            "4     True\n",
            "Name: Age, dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (df[df['Age'] > 17])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxnVLgsSMYjj",
        "outputId": "3ff107b2-10cb-4079-b9ad-15fcd05eac32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Name  Age  Marks\n",
            "0  Alice   18     85\n",
            "1    Bob   19     92\n",
            "3  David   20     95\n",
            "4    Eve   18     88\n"
          ]
        }
      ]
    },
    {
      "source": [
        "print(df[df['Age'] > 17]['Age']) # Select the 'Age' column after filtering the DataFrame"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oztTv9l-O4Y-",
        "outputId": "db7c4bff-e1b3-45f6-f7dd-402de2d23a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    18\n",
            "1    19\n",
            "3    20\n",
            "4    18\n",
            "Name: Age, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Reading a gff file from a path and returning it in to a dataframe.**"
      ],
      "metadata": {
        "id": "xQKC6rAb3xYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Read a gff file from a path and return a data frame. Also add attributes into the column\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def parse_gff_to_df(gff_file):\n",
        "  \"\"\"\n",
        "  Parses a GFF file and returns a pandas DataFrame of features.\n",
        "\n",
        "  Args:\n",
        "    gff_file: Path to the GFF file.\n",
        "\n",
        "  Returns:\n",
        "    A pandas DataFrame representing the features in the GFF file.\n",
        "  \"\"\"\n",
        "  features = []\n",
        "  with open(gff_file, 'r') as f:\n",
        "    for line in f:\n",
        "      if line.startswith('#'):\n",
        "        continue\n",
        "      fields = line.strip().split('\\t')\n",
        "      if len(fields) >= 9:\n",
        "        seqid, source, ftype, start, end, score, strand, phase, attributes = fields[:9]\n",
        "        attr_dict = {}\n",
        "        for attr in attributes.split(';'):\n",
        "          if '=' in attr:\n",
        "            key, value = attr.split('=')\n",
        "            attr_dict[key] = value\n",
        "\n",
        "        feature = {\n",
        "            'seqid': seqid,\n",
        "            'source': source,\n",
        "            'type': ftype,\n",
        "            'start': int(start),\n",
        "            'end': int(end),\n",
        "            'score': score,\n",
        "            'strand': strand,\n",
        "            'phase': phase,\n",
        "            **attr_dict  # Add attributes as columns\n",
        "        }\n",
        "        features.append(feature)\n",
        "  return pd.DataFrame(features)\n",
        "\n"
      ],
      "metadata": {
        "id": "O9BRLuDHQCR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: upload a file\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "popjm9V7jhr8",
        "outputId": "7593dd21-4c58-43d0-d66d-d7f18d0c9667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fae14a7a-b2b1-493c-ade8-80f5651280ba\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fae14a7a-b2b1-493c-ade8-80f5651280ba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving W3110.gff to W3110 (1).gff\n",
            "User uploaded file \"W3110 (1).gff\" with length 7224073 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Read this gff file W3110.gff\n",
        "\n",
        "gff_file_path = 'W3110.gff'  # Assuming the uploaded file is named 'W3110.gff'\n",
        "df_gff = parse_gff_to_df(gff_file_path)\n",
        "print(df_gff.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjzuVCCYj3XU",
        "outputId": "3a4dd772-3abd-4639-9ba2-e58992314ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         seqid            source              type  start      end score  \\\n",
            "0  NC_007779.1            RefSeq            region      1  4646332     .   \n",
            "1  NC_007779.1            RefSeq              gene    190      255     .   \n",
            "2  NC_007779.1  Protein Homology               CDS    190      255     .   \n",
            "3  NC_007779.1          cmsearch  sequence_feature    191      310     .   \n",
            "4  NC_007779.1            RefSeq              gene    337     2799     .   \n",
            "\n",
            "  strand phase                                  ID                  Dbxref  \\\n",
            "0      +     .  a99aee7d8774ee1318b35b64abeb3eab_1            taxon:316407   \n",
            "1      +     .  a99aee7d8774ee1318b35b64abeb3eab_2                     NaN   \n",
            "2      +     0  a99aee7d8774ee1318b35b64abeb3eab_3  Genbank:WP_001386572.1   \n",
            "3      +     .  a99aee7d8774ee1318b35b64abeb3eab_4            RFAM:RF00506   \n",
            "4      +     .  a99aee7d8774ee1318b35b64abeb3eab_5                     NaN   \n",
            "\n",
            "   ... start_range bound_moiety regulatory_class anticodon exception  \\\n",
            "0  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "1  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "2  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "3  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "4  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "\n",
            "  transl_except rpt_family rpt_type rpt_unit_range rpt_unit_seq  \n",
            "0           NaN        NaN      NaN            NaN          NaN  \n",
            "1           NaN        NaN      NaN            NaN          NaN  \n",
            "2           NaN        NaN      NaN            NaN          NaN  \n",
            "3           NaN        NaN      NaN            NaN          NaN  \n",
            "4           NaN        NaN      NaN            NaN          NaN  \n",
            "\n",
            "[5 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"seqid\", \"source\", \"type\", \"start\", \"end\", \"strand\", \"ID\", \"gene\"]"
      ],
      "metadata": {
        "id": "eW3FIFNDmdF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4jDnBFp9UoM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print rows where gene = pdeG and print only these columns\n",
        "\n",
        "filtered_df = df_gff[(df_gff['gene'] == 'pdeG')][columns]\n",
        "print(filtered_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZZA78Ool-tN",
        "outputId": "51b6e9ea-2ef8-48ca-fd7f-28f3ca625e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            seqid            source  type    start      end strand  \\\n",
            "2422  NC_007779.1            RefSeq  gene  1218905  1220428      +   \n",
            "2423  NC_007779.1  Protein Homology   CDS  1218905  1220428      +   \n",
            "\n",
            "                                         ID  gene  \n",
            "2422  a99aee7d8774ee1318b35b64abeb3eab_2423  pdeG  \n",
            "2423  a99aee7d8774ee1318b35b64abeb3eab_2424  pdeG  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_gene_data(df_gff, gene_name, neigboring_genes_count = 6):\n",
        "  # Find the row with the given gene\n",
        "  row = df_gff[df_gff['gene'] == gene_name]\n",
        "\n",
        "  if not row.empty:\n",
        "    index = row.index[0]\n",
        "\n",
        "    # Find the indices of upstream and downstream genes\n",
        "    upstream_indices = range(max(0, index - neigboring_genes_count), index)\n",
        "    downstream_indices = range(index + 1, min(len(df_gff), index + neigboring_genes_count + 1))\n",
        "\n",
        "    # Extract the upstream and downstream genes\n",
        "    upstream_genes = df_gff.loc[upstream_indices]\n",
        "    downstream_genes = df_gff.loc[downstream_indices]\n",
        "\n",
        "    # Print the upstream and downstream genes\n",
        "    print(\"Upstream Genes:\")\n",
        "    print(upstream_genes)\n",
        "    print(\"\\nDownstream Genes:\")\n",
        "    print(downstream_genes)\n",
        "  else:\n",
        "    print(\"gene not found in the GFF file.\")\n",
        "\n",
        "  return upstream_genes, downstream_genes"
      ],
      "metadata": {
        "id": "wah3g1lTpo7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_columns(df_gff, columns):\n",
        "  return df_gff[columns]"
      ],
      "metadata": {
        "id": "2poD3wza1C5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upstream_genes, downstream_genes = extract_gene_data(df_gff, \"pdeG\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij6XDIZfzm27",
        "outputId": "70b54db2-267e-435c-b1e2-6c1356392925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upstream Genes:\n",
            "            seqid            source  type    start      end score strand  \\\n",
            "2416  NC_007779.1            RefSeq  gene  1217645  1217917     .      +   \n",
            "2417  NC_007779.1  Protein Homology   CDS  1217645  1217917     .      +   \n",
            "2418  NC_007779.1            RefSeq  gene  1217946  1218212     .      +   \n",
            "2419  NC_007779.1  Protein Homology   CDS  1217946  1218212     .      +   \n",
            "2420  NC_007779.1            RefSeq  gene  1218325  1218573     .      +   \n",
            "2421  NC_007779.1  Protein Homology   CDS  1218325  1218573     .      +   \n",
            "\n",
            "     phase                                     ID                  Dbxref  \\\n",
            "2416     .  a99aee7d8774ee1318b35b64abeb3eab_2417                     NaN   \n",
            "2417     0  a99aee7d8774ee1318b35b64abeb3eab_2418  Genbank:WP_000858002.1   \n",
            "2418     .  a99aee7d8774ee1318b35b64abeb3eab_2419                     NaN   \n",
            "2419     0  a99aee7d8774ee1318b35b64abeb3eab_2420  Genbank:WP_000888772.1   \n",
            "2420     .  a99aee7d8774ee1318b35b64abeb3eab_2421                     NaN   \n",
            "2421     0  a99aee7d8774ee1318b35b64abeb3eab_2422  Genbank:WP_001065752.1   \n",
            "\n",
            "      ... start_range bound_moiety regulatory_class anticodon exception  \\\n",
            "2416  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "2417  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "2418  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "2419  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "2420  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "2421  ...         NaN          NaN              NaN       NaN       NaN   \n",
            "\n",
            "     transl_except rpt_family rpt_type rpt_unit_range rpt_unit_seq  \n",
            "2416           NaN        NaN      NaN            NaN          NaN  \n",
            "2417           NaN        NaN      NaN            NaN          NaN  \n",
            "2418           NaN        NaN      NaN            NaN          NaN  \n",
            "2419           NaN        NaN      NaN            NaN          NaN  \n",
            "2420           NaN        NaN      NaN            NaN          NaN  \n",
            "2421           NaN        NaN      NaN            NaN          NaN  \n",
            "\n",
            "[6 rows x 41 columns]\n",
            "\n",
            "Downstream Genes:\n",
            "            seqid            source        type    start      end score  \\\n",
            "2423  NC_007779.1  Protein Homology         CDS  1218905  1220428     .   \n",
            "2424  NC_007779.1            RefSeq        gene  1220560  1220778     .   \n",
            "2425  NC_007779.1  Protein Homology         CDS  1220560  1220778     .   \n",
            "2426  NC_007779.1            RefSeq  pseudogene  1221178  1223825     .   \n",
            "2427  NC_007779.1  Protein Homology         CDS  1221178  1223825     .   \n",
            "2428  NC_007779.1            RefSeq        gene  1223882  1224217     .   \n",
            "\n",
            "     strand phase                                     ID  \\\n",
            "2423      +     0  a99aee7d8774ee1318b35b64abeb3eab_2424   \n",
            "2424      +     .  a99aee7d8774ee1318b35b64abeb3eab_2425   \n",
            "2425      +     0  a99aee7d8774ee1318b35b64abeb3eab_2426   \n",
            "2426      +     .  a99aee7d8774ee1318b35b64abeb3eab_2427   \n",
            "2427      +     0  a99aee7d8774ee1318b35b64abeb3eab_2428   \n",
            "2428      -     .  a99aee7d8774ee1318b35b64abeb3eab_2429   \n",
            "\n",
            "                      Dbxref  ... start_range bound_moiety regulatory_class  \\\n",
            "2423  Genbank:WP_001246499.1  ...         NaN          NaN              NaN   \n",
            "2424                     NaN  ...         NaN          NaN              NaN   \n",
            "2425  Genbank:WP_001065861.1  ...         NaN          NaN              NaN   \n",
            "2426                     NaN  ...         NaN          NaN              NaN   \n",
            "2427                     NaN  ...         NaN          NaN              NaN   \n",
            "2428                     NaN  ...         NaN          NaN              NaN   \n",
            "\n",
            "     anticodon exception transl_except rpt_family rpt_type rpt_unit_range  \\\n",
            "2423       NaN       NaN           NaN        NaN      NaN            NaN   \n",
            "2424       NaN       NaN           NaN        NaN      NaN            NaN   \n",
            "2425       NaN       NaN           NaN        NaN      NaN            NaN   \n",
            "2426       NaN       NaN           NaN        NaN      NaN            NaN   \n",
            "2427       NaN       NaN           NaN        NaN      NaN            NaN   \n",
            "2428       NaN       NaN           NaN        NaN      NaN            NaN   \n",
            "\n",
            "     rpt_unit_seq  \n",
            "2423          NaN  \n",
            "2424          NaN  \n",
            "2425          NaN  \n",
            "2426          NaN  \n",
            "2427          NaN  \n",
            "2428          NaN  \n",
            "\n",
            "[6 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(select_columns(upstream_genes, columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRBXBeYr2EEP",
        "outputId": "63ad4791-7e2c-4f42-f628-046bf06cad83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            seqid            source  type    start      end strand  \\\n",
            "2416  NC_007779.1            RefSeq  gene  1217645  1217917      +   \n",
            "2417  NC_007779.1  Protein Homology   CDS  1217645  1217917      +   \n",
            "2418  NC_007779.1            RefSeq  gene  1217946  1218212      +   \n",
            "2419  NC_007779.1  Protein Homology   CDS  1217946  1218212      +   \n",
            "2420  NC_007779.1            RefSeq  gene  1218325  1218573      +   \n",
            "2421  NC_007779.1  Protein Homology   CDS  1218325  1218573      +   \n",
            "\n",
            "                                         ID  gene  \n",
            "2416  a99aee7d8774ee1318b35b64abeb3eab_2417  ymgA  \n",
            "2417  a99aee7d8774ee1318b35b64abeb3eab_2418  ymgA  \n",
            "2418  a99aee7d8774ee1318b35b64abeb3eab_2419  ariR  \n",
            "2419  a99aee7d8774ee1318b35b64abeb3eab_2420  ariR  \n",
            "2420  a99aee7d8774ee1318b35b64abeb3eab_2421   NaN  \n",
            "2421  a99aee7d8774ee1318b35b64abeb3eab_2422   NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(select_columns(downstream_genes, columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AhdsBlt2Krj",
        "outputId": "7a4104ae-64a2-478f-bf58-b00c68be396b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            seqid            source        type    start      end strand  \\\n",
            "2423  NC_007779.1  Protein Homology         CDS  1218905  1220428      +   \n",
            "2424  NC_007779.1            RefSeq        gene  1220560  1220778      +   \n",
            "2425  NC_007779.1  Protein Homology         CDS  1220560  1220778      +   \n",
            "2426  NC_007779.1            RefSeq  pseudogene  1221178  1223825      +   \n",
            "2427  NC_007779.1  Protein Homology         CDS  1221178  1223825      +   \n",
            "2428  NC_007779.1            RefSeq        gene  1223882  1224217      -   \n",
            "\n",
            "                                         ID  gene  \n",
            "2423  a99aee7d8774ee1318b35b64abeb3eab_2424  pdeG  \n",
            "2424  a99aee7d8774ee1318b35b64abeb3eab_2425   NaN  \n",
            "2425  a99aee7d8774ee1318b35b64abeb3eab_2426   NaN  \n",
            "2426  a99aee7d8774ee1318b35b64abeb3eab_2427   NaN  \n",
            "2427  a99aee7d8774ee1318b35b64abeb3eab_2428   NaN  \n",
            "2428  a99aee7d8774ee1318b35b64abeb3eab_2429  ymgD  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_all_gff_file_paths(directory):\n",
        "  \"\"\"\n",
        "  Returns a list of complete paths to all GFF files within a directory.\n",
        "\n",
        "  Args:\n",
        "    directory: The directory to search for GFF files.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings, each representing a complete path to a GFF file.\n",
        "  \"\"\"\n",
        "  gff_file_paths = []\n",
        "  for root, _, files in os.walk(directory):\n",
        "    for file in files:\n",
        "      if file.endswith('.gff'):\n",
        "        gff_file_paths.append(os.path.join(root, file))\n",
        "  return gff_file_paths\n",
        "print(get_all_gff_file_paths('/scratch/zxx091000/fromMZ/Databases/Ecoli/Roary.April2024/results/fixed_input_files'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V63CmUFC068g",
        "outputId": "97fa30a3-3400-444e-8bd4-06aafb7c6263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing each gff file and returning into dataframe."
      ],
      "metadata": {
        "id": "QVT4H0VIOyDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gff_directory = '/scratch/zxx091000/fromMZ/Databases/Ecoli/Roary.April2024/results/fixed_input_files'\n",
        "gff_file_paths = get_all_gff_file_paths(gff_directory)   #list of gff file path, list of strings\n",
        "\n",
        "for gff_file_path in gff_file_paths:\n",
        "  try:\n",
        "    df_gff = parse_gff_to_df(gff_file_path)\n",
        "    all_gff_dfs.append(df_gff)\n",
        "    print(f\"Processed GFF file: {gff_file_path}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error processing GFF file {gff_file_path}: {e}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2c50GAnMUGNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_gene_data(df_gff, gene_name, neighboring_genes_count=6):\n",
        "  \"\"\"\n",
        "  Extracts upstream and downstream genes for a given gene from a GFF DataFrame.\n",
        "\n",
        "  Args:\n",
        "    df_gff: A pandas DataFrame representing the GFF file.\n",
        "    gene_name: The name of the gene to find upstream and downstream genes for.\n",
        "    neighboring_genes_count: The number of neighboring genes to extract on each side.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing upstream_genes and downstream_genes DataFrames.\n",
        "  \"\"\"\n",
        "  # Find the row with the given gene\n",
        "  row = df_gff[df_gff['gene'] == gene_name]\n",
        "\n",
        "  if not row.empty:\n",
        "    index = row.index[0]\n",
        "\n",
        "    # Find the indices of upstream and downstream genes\n",
        "    upstream_indices = range(max(0, index - neighboring_genes_count), index)\n",
        "    downstream_indices = range(index + 1, min(len(df_gff), index + neighboring_genes_count + 1))\n",
        "\n",
        "    # Extract the upstream and downstream genes\n",
        "    upstream_genes = df_gff.loc[upstream_indices]\n",
        "    downstream_genes = df_gff.loc[downstream_indices]\n",
        "\n",
        "    return upstream_genes, downstream_genes\n",
        "  else:\n",
        "    print(f\"Gene '{gene_name}' not found in the GFF file.\")\n",
        "    return None, None\n"
      ],
      "metadata": {
        "id": "1GLhNBZvWenU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gff_directory = '/scratch/zxx091000/fromMZ/Databases/Ecoli/Roary.April2024/results/fixed_input_files'\n",
        "gff_file_paths = get_all_gff_file_paths(gff_directory)\n",
        "gene_names_to_filter = ['pdeG', '\"pdeG\"'] # Specify the gene name to filter for\n",
        "columns = [\"seqid\", \"source\", \"type\", \"start\", \"end\", \"strand\", \"ID\", \"gene\"]\n",
        "\n",
        "for gff_file_path in gff_file_paths:\n",
        "  try:\n",
        "    df_gff = parse_gff_to_df(gff_file_path)\n",
        "    print(f\"Processed GFF file: {gff_file_path}\") #printing processed file\n",
        "    for gene_name_to_filter in gene_names_to_filter:\n",
        "        # Filter for gene and extract upstream and downstream genes\n",
        "        upstream_genes, downstream_genes = extract_gene_data(df_gff, gene_name_to_filter)\n",
        "        if upstream_genes is not None and downstream_genes is not None:\n",
        "          print(f\"Upstream genes for {gene_name_to_filter} in {gff_file_path}:\")\n",
        "          print(upstream_genes[columns])\n",
        "          print(f\"Downstream genes for {gene_name_to_filter} in {gff_file_path}:\")\n",
        "          print(downstream_genes[columns])\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error processing GFF file {gff_file_path}: {e}\")"
      ],
      "metadata": {
        "id": "iFGL1IjrgNzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step 6: Define the extract gene data function\")\n",
        "def extract_gene_data(df_gff, gene_name, neighboring_genes_count=6):\n",
        "  \"\"\"\n",
        "  Extracts upstream and downstream genes for a given gene from a GFF DataFrame.\n",
        "\n",
        "  Args:\n",
        "    df_gff: A pandas DataFrame representing the GFF file.\n",
        "    gene_name: The name of the gene to find upstream and downstream genes for.\n",
        "    neighboring_genes_count: The number of neighboring genes to extract on each side.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing upstream_genes and downstream_genes DataFrames.\n",
        "  \"\"\"\n",
        "  # Finding the row with the given gene\n",
        "  row = df_gff[df_gff['gene'].str.contains(gene_name, regex=False, na=False)]\n",
        "\n",
        "  if not row.empty:\n",
        "    index = row.index[0]\n",
        "\n",
        "    # Finding the indices of upstream and downstream genes\n",
        "    upstream_indices = range(max(0, index - neighboring_genes_count), index)\n",
        "    downstream_indices = range(index + 1, min(len(df_gff), index + neighboring_genes_count + 1))\n",
        "\n",
        "    # Extracting the upstream and downstream genes\n",
        "    upstream_genes = df_gff.loc[upstream_indices]\n",
        "    downstream_genes = df_gff.loc[downstream_indices]\n",
        "\n",
        "    return upstream_genes, downstream_genes, row\n",
        "  else:\n",
        "    print(f\"Gene '{gene_name}' not found in the GFF file.\")\n",
        "    return None, None, None"
      ],
      "metadata": {
        "id": "srGA5LjcNf9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CHANGE THE GENE NAME HERE\n",
        "print(\"Step7: Adding filter to the gene names, Extracting the gene information upstream and downstream genes and writing into a csv\")\n",
        "import os\n",
        "import numpy as np  # Importing numpy to add NaN for the blank line\n",
        "\n",
        "gff_directory = '/scratch/zxx091000/fromMZ/Databases/Ecoli/Roary.April2024/results/fixed_input_files'\n",
        "gff_file_paths = get_all_gff_file_paths(gff_directory)\n",
        "gene_names_to_filter = ['phnP']  # Specify the gene name to filter for\n",
        "columns = [\"seqid\", \"source\", \"type\", \"start\", \"end\", \"strand\", \"ID\", \"gene\"]\n",
        "complete_gene_info = []\n",
        "\n",
        "for gff_file_path in gff_file_paths:\n",
        "    try:\n",
        "        df_gff = parse_gff_to_df(gff_file_path)\n",
        "        print(f\"Processed GFF file: {gff_file_path}\")\n",
        "\n",
        "        # Handling Strip quotes from gene names to handle cases like \"pdeG\" present in some of the files\n",
        "        df_gff['gene'] = df_gff['gene'].astype(str).str.strip('\"')\n",
        "\n",
        "        for gene_name_to_filter in gene_names_to_filter:\n",
        "\n",
        "            # Ensure extract_gene_data returns only 3 values\n",
        "            result = extract_gene_data(df_gff, gene_name_to_filter)\n",
        "            if len(result) != 3:\n",
        "                raise ValueError(f\"Expected 3 values from extract_gene_data, but got {len(result)}\")\n",
        "\n",
        "            upstream_genes, downstream_genes, phnP_row = result   ## CHANGE THE GENE NAME HERE\n",
        "\n",
        "            if upstream_genes is not None and downstream_genes is not None:\n",
        "                # Adding upstream genes to the list in their correct order (closest upstream first)\n",
        "                for i, (index, row) in enumerate(upstream_genes.iterrows(), start=1):\n",
        "                    gene_info = {\n",
        "                        'gene_name': row.get('gene', ''),\n",
        "                        'gff_file': os.path.basename(gff_file_path),\n",
        "                        'relationship': 'upstream',\n",
        "                        'position': i,  # Numbering for upstream genes starting from closest to the gene searching for\n",
        "                        'seqid': row['seqid'],\n",
        "                        'source': row['source'],\n",
        "                        'type': row['type'],\n",
        "                        'start': row['start'],\n",
        "                        'end': row['end'],\n",
        "                        'strand': row['strand'],\n",
        "                        'ID': row.get('ID', '')\n",
        "                    }\n",
        "                    complete_gene_info.append(gene_info)\n",
        "\n",
        "                # Adding the central labelled as self. Also CHANGE THE GENE NAME HERE\n",
        "                for index, row in phnP_row.iterrows():\n",
        "                    gene_info = {\n",
        "                        'gene_name': row.get('gene', ''),\n",
        "                        'gff_file': os.path.basename(gff_file_path),\n",
        "                        'relationship': 'self',\n",
        "                        'position': '',  # No numbering for the gene itself\n",
        "                        'seqid': row['seqid'],\n",
        "                        'source': row['source'],\n",
        "                        'type': row['type'],\n",
        "                        'start': row['start'],\n",
        "                        'end': row['end'],\n",
        "                        'strand': row['strand'],\n",
        "                        'ID': row.get('ID', '')\n",
        "                    }\n",
        "                    complete_gene_info.append(gene_info)\n",
        "\n",
        "                # Adding downstream genes to the list in their original order (closest downstream first)\n",
        "                for i, (index, row) in enumerate(downstream_genes.iterrows(), start=1):\n",
        "                    gene_info = {\n",
        "                        'gene_name': row.get('gene', ''),\n",
        "                        'gff_file': os.path.basename(gff_file_path),\n",
        "                        'relationship': 'downstream',\n",
        "                        'position': i,  # Numbering for downstream genes starting from closest to pdeG\n",
        "                        'seqid': row['seqid'],\n",
        "                        'source': row['source'],\n",
        "                        'type': row['type'],\n",
        "                        'start': row['start'],\n",
        "                        'end': row['end'],\n",
        "                        'strand': row['strand'],\n",
        "                        'ID': row.get('ID', '')\n",
        "                    }\n",
        "                    complete_gene_info.append(gene_info)\n",
        "\n",
        "        # Appending a blank row to separate data for each GFF file**\n",
        "        blank_row = {col: np.nan for col in ['gene_name', 'gff_file', 'relationship', 'position', 'seqid', 'source', 'type', 'start', 'end', 'strand', 'ID']}\n",
        "        complete_gene_info.append(blank_row)\n",
        "\n",
        "    except ValueError as ve:\n",
        "       print(f\"ValueError in {gff_file_path}: {ve}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing GFF file {gff_file_path}: {e}\")\n",
        "\n",
        "# Creating a DataFrame from the collected gene data\n",
        "gene_df = pd.DataFrame(complete_gene_info)\n",
        "\n",
        "# Saving the DataFrame to a CSV file\n",
        "gene_df.to_csv('phnP_gene_information.csv', index=False)\n",
        "\n",
        "print(\"Gene information written to phnP_gene_information.csv\")\n"
      ],
      "metadata": {
        "id": "sPgpETMiNhMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2JOBbm2ehUC8"
      }
    }
  ]
}